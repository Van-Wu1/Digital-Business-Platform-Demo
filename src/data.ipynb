{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d939e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13921381",
   "metadata": {},
   "source": [
    "### 数据清理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f69840",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72e086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef72e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to 'summary_result.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# 汇总省级数据\n",
    "province_summary = df.groupby(['province'], as_index=False).agg({\n",
    "    'sales_rmb': 'sum',\n",
    "    'revenue_rmb': 'sum'\n",
    "})\n",
    "\n",
    "# 汇总城市级数据，保留省级信息\n",
    "city_summary = df.groupby(['province', 'city'], as_index=False).agg({\n",
    "    'sales_rmb': 'sum',\n",
    "    'revenue_rmb': 'sum'\n",
    "})\n",
    "\n",
    "# 汇总区域级数据，保留省级和城市级信息\n",
    "district_summary = df.groupby(['province', 'city', 'district'], as_index=False).agg({\n",
    "    'sales_rmb': 'sum',\n",
    "    'revenue_rmb': 'sum'\n",
    "})\n",
    "\n",
    "# 创建一个Excel writer对象，保存三个sheet\n",
    "with pd.ExcelWriter(\"../docs/sample/A_summary_result.xlsx\") as writer:\n",
    "    province_summary.to_excel(writer, sheet_name=\"Province Summary\", index=False)\n",
    "    city_summary.to_excel(writer, sheet_name=\"City Summary\", index=False)\n",
    "    district_summary.to_excel(writer, sheet_name=\"District Summary\", index=False)\n",
    "\n",
    "print(\"Data cleaned and saved to 'summary_result.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0495c5",
   "metadata": {},
   "source": [
    "### 数据矫正\n",
    "shapefile投影矫正到84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098d50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载空间数据（省级、市级、区级轮廓的GeoJSON文件）\n",
    "province_gdf = gpd.read_file(\"../data/raw/province_geo.geojson\")  # 省级GeoJSON\n",
    "city_gdf = gpd.read_file(\"../data/raw/city_geo.geojson\")          # 市级GeoJSON\n",
    "district_gdf = gpd.read_file(\"../data/raw/district_geo.geojson\")  # 区级GeoJSON\n",
    "\n",
    "# 将所有的GeoDataFrame投影到WGS 84 (EPSG:4326)\n",
    "province_gdf = province_gdf.to_crs(epsg=4326)\n",
    "city_gdf = city_gdf.to_crs(epsg=4326)\n",
    "district_gdf = district_gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b49809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 读取 geojson 文件\n",
    "# geojson_file = \"./shp/district_geo.geojson\"\n",
    "# gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "# # 打印列名\n",
    "# print(\"列名:\", gdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d6437",
   "metadata": {},
   "source": [
    "### 空间连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9abf9a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空间连接完成，结果已保存到'spatial_join_results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# 将 lat 和 lon 转换为 GeoDataFrame 中的几何列\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(df['lon'], df['lat'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# 4. 确保数据的 CRS 设置为 WGS 84 (EPSG:4326)，如果数据没有 CRS 信息\n",
    "gdf = gdf.set_crs(epsg=4326, allow_override=True)\n",
    "\n",
    "# 5. 空间连接：通过空间连接将省级、市级、区级的轮廓与数据连接\n",
    "province_join = gpd.sjoin(gdf, province_gdf, how=\"left\", predicate=\"within\")\n",
    "city_join = gpd.sjoin(gdf, city_gdf, how=\"left\", predicate=\"within\")\n",
    "district_join = gpd.sjoin(gdf, district_gdf, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# 6. 检查是否有错误：比较空间连接结果和原数据中的省、市、区信息\n",
    "province_join['error_province'] = (province_join['province'] != province_join['name']).astype(int)\n",
    "city_join['error_city'] = (city_join['city'] != city_join['name']).astype(int)\n",
    "district_join['error_district'] = (district_join['district'] != district_join['name']).astype(int)\n",
    "\n",
    "# 7. 合并结果，生成新的列（省、市、区的空间连接结果和错误标记）\n",
    "result = df.copy()\n",
    "result['province_geo'] = province_join['name']\n",
    "result['city_geo'] = city_join['name']\n",
    "result['district_geo'] = district_join['name']\n",
    "result['error_flag'] = (province_join['error_province'] | city_join['error_city'] | district_join['error_district']).astype(int)\n",
    "\n",
    "# 8. 保存为新的Excel文件\n",
    "result.to_excel(\"../docs/sample/spatial_join_results.xlsx\", index=False)\n",
    "\n",
    "print(\"空间连接完成，结果已保存到'spatial_join_results.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c3ecf",
   "metadata": {},
   "source": [
    "### 建立geojson （轮廓+交易额）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6bb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入矫正之后的csv\n",
    "# 可能在此之前还要加一段修正代码，但也可能是人为修正，具体看后面的数据来补代码\n",
    "# df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55577aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON files for province, city, and district summaries saved.\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "# 汇总省级数据\n",
    "province_summary = df.groupby(['province'], as_index=False).agg({\n",
    "    'sales_rmb': 'sum',\n",
    "    'revenue_rmb': 'sum'\n",
    "})\n",
    "\n",
    "# 汇总城市级数据，保留省级信息\n",
    "city_summary = df.groupby(['province', 'city'], as_index=False).agg({\n",
    "    'sales_rmb': 'sum',\n",
    "    'revenue_rmb': 'sum'\n",
    "})\n",
    "\n",
    "# 汇总区域级数据，保留省级和城市级信息\n",
    "district_summary = df.groupby(['province', 'city', 'district'], as_index=False).agg({\n",
    "    'sales_rmb': 'sum',\n",
    "    'revenue_rmb': 'sum'\n",
    "})\n",
    "\n",
    "# 结合汇总数据与对应的GeoJSON文件\n",
    "# 假设省级数据的GeoJSON文件包含一个名为 'name' 的字段，城市和区级文件也是如此\n",
    "# 将汇总数据与省、市、区的几何信息合并\n",
    "\n",
    "# 合并省级数据\n",
    "province_gdf = province_gdf.merge(province_summary, left_on=\"name\", right_on=\"province\", how=\"left\")\n",
    "\n",
    "# 合并城市级数据\n",
    "city_gdf = city_gdf.merge(city_summary, left_on=\"name\", right_on=\"city\", how=\"left\")\n",
    "\n",
    "# 合并区级数据\n",
    "district_gdf = district_gdf.merge(district_summary, left_on=\"name\", right_on=\"district\", how=\"left\")\n",
    "\n",
    "# 保存为GeoJSON文件\n",
    "province_gdf.to_file(\"../data/shp/province_summary.geojson\", driver=\"GeoJSON\")\n",
    "city_gdf.to_file(\"../data/shp/city_summary.geojson\", driver=\"GeoJSON\")\n",
    "district_gdf.to_file(\"../data/shp/district_summary.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"GeoJSON files for province, city, and district summaries saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138f425",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133b1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "\n",
    "# def safe_deduplicate_with_null_protection(input_file, output_file):\n",
    "#     print(f\"正在分析文件: {input_file}\")\n",
    "#     gdf = gpd.read_file(input_file)\n",
    "    \n",
    "#     # 1. 定义四维度字段\n",
    "#     cols = ['province', 'city', 'district', 'name']\n",
    "\n",
    "#     # 2. 筛选出：四项全都有值 的数据\n",
    "#     # notnull().all(axis=1) 确保这四个字段一个 null 都没有\n",
    "#     complete_data_mask = gdf[cols].notnull().all(axis=1)\n",
    "#     gdf_complete = gdf[complete_data_mask].copy()\n",
    "    \n",
    "#     # 3. 在完整数据中找重复\n",
    "#     # 使用 keep=False 标记所有参与重复的行\n",
    "#     dup_mask = gdf_complete.duplicated(subset=cols, keep=False)\n",
    "    \n",
    "#     if dup_mask.any():\n",
    "#         to_dissolve = gdf_complete[dup_mask].copy()\n",
    "#         # 剩下的数据：包括包含 null 的行，以及不重复的完整行\n",
    "#         to_keep_as_is = gdf[~complete_data_mask | (complete_data_mask & ~dup_mask)].copy()\n",
    "\n",
    "#         print(\"\\n\" + \"!\"*60)\n",
    "#         print(f\"发现以下【四项全满且完全一致】的重复项，准备进行合并：\")\n",
    "#         print(to_dissolve[cols + ['gb', 'revenue_rmb']].to_string(index=False))\n",
    "#         print(\"!\"*60 + \"\\n\")\n",
    "\n",
    "#         # 4. 仅对重复项进行聚合\n",
    "#         # 按四维度聚合，累加业务数值\n",
    "#         dissolved_part = to_dissolve.dissolve(by=cols, aggfunc={\n",
    "#             'revenue_rmb': 'sum',\n",
    "#             'sales_rmb': 'sum',\n",
    "#             'gb': 'first' # gb 码保留遇到的第一个\n",
    "#         }).reset_index()\n",
    "\n",
    "#         # 5. 合并回原始数据（保留了所有 null 行和唯一行）\n",
    "#         final_gdf = pd.concat([to_keep_as_is, dissolved_part], ignore_index=True)\n",
    "        \n",
    "#         print(f\"合并完成：原始重复行已合成为 {len(dissolved_part)} 条记录。\")\n",
    "#     else:\n",
    "#         print(\"\\n未发现【四项全满且完全一致】的重复记录，保持原样。\")\n",
    "#         final_gdf = gdf\n",
    "\n",
    "#     # 保存\n",
    "#     final_gdf.to_file(output_file, driver='GeoJSON')\n",
    "#     print(f\"\\n最终统计：\")\n",
    "#     print(f\"原始记录总数: {len(gdf)}\")\n",
    "#     print(f\"去重后总数: {len(final_gdf)}\")\n",
    "#     print(f\"结果已存至: {output_file}\")\n",
    "\n",
    "# # 执行\n",
    "# safe_deduplicate_with_null_protection('district_summary.geojson', 'district_summary_fixed.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
